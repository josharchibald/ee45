{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow import keras\n",
    "import random\n",
    "import cv2\n",
    "import math\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import json\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D,Convolution2D,BatchNormalization\n",
    "from tensorflow.keras.layers import Flatten,MaxPooling2D,Dropout\n",
    "\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.applications.densenet import preprocess_input\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import load_img,ImageDataGenerator,img_to_array\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function keras.src.applications.densenet.DenseNet121(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model Architechture\n",
    "model_d = DenseNet121(weights=None,include_top=False, input_shape=(32, 32, 3)) \n",
    "x = model_d.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation='relu')(x) \n",
    "x = Dense(512, activation='relu')(x) \n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "preds = Dense(3, activation='softmax')(x) #FC-layer\n",
    "\n",
    "model = Model(inputs=model_d.input,outputs=preds)\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "for layer in model.layers[:-8]:\n",
    "    layer.trainable=False\n",
    "\n",
    "for layer in model.layers[-8:]:\n",
    "    layer.trainable=True\n",
    "\n",
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "EPOCHS = 10\n",
    "CHECKPOINT_NAME = 'checkpoints'\n",
    "\n",
    "label_dict = {'fivefingerR': 0, 'fourfingerR': 1, 'threefingerR': 2, 'twofingerR': 3, 'onefingerR': 4, \n",
    "              'fistR': 5, 'cowabungaR': 6, 'spidermanR': 7, 'okR': 8, 'cR': 9, 'thumbR': 10, \n",
    "              'lR': 11, 'oR': 12, 'rockonR': 13, 'palmR': 14, 'sidehandR': 15}\n",
    "\n",
    "with open('data_pad.json', 'r') as file:\n",
    "    raw_data = json.load(file)\n",
    "\n",
    "labels = np.array([])\n",
    "data = np.array([])\n",
    "\n",
    "for label, arrays in raw_data.items():\n",
    "    for array in arrays:\n",
    "        labels = np.append(labels, label_dict[label])\n",
    "        normalizedData = (array-np.min(array))/(np.max(array)-np.min(array))\n",
    "        data = np.append(data, normalizedData)\n",
    "        \n",
    "# print(data)\n",
    "# print(labels)\n",
    "# mlb = LabelBinarizer()\n",
    "# labels = mlb.fit_transform(labels)\n",
    "# print(labels[1])\n",
    "\n",
    "(xtrain,xtest,ytrain,ytest)=train_test_split(data,labels,test_size=0.4)\n",
    "print(xtrain.shape, xtest.shape)\n",
    "\n",
    "# anne = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, verbose=1, min_lr=1e-3)\n",
    "# checkpoint = ModelCheckpoint(CHECKPOINT_NAME, verbose=1, save_best_only=True)\n",
    "# datagen = ImageDataGenerator(zoom_range = 0.2, horizontal_flip=True, shear_range=0.2)\n",
    "# datagen.fit(xtrain)\n",
    "\n",
    "# Fits-the-model\n",
    "# history = model.fit_generator(datagen.flow(xtrain, ytrain, batch_size=128),\n",
    "#                steps_per_epoch=xtrain.shape[0] //128,\n",
    "#                epochs=EPOCHS,\n",
    "#                verbose=2,\n",
    "#                validation_data=(xtrain, ytrain))\n",
    "\n",
    "model_t = model.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'path/to/your/image.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Load the image\u001b[39;00m\n\u001b[1;32m      2\u001b[0m image_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpath/to/your/image.jpg\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m image \u001b[39m=\u001b[39m load_img(image_path, target_size\u001b[39m=\u001b[39;49m(\u001b[39m32\u001b[39;49m, \u001b[39m32\u001b[39;49m))  \u001b[39m# Resize the image to match the input size of the CNN\u001b[39;00m\n\u001b[1;32m      4\u001b[0m image_array \u001b[39m=\u001b[39m img_to_array(image)  \u001b[39m# Convert the image to a numpy array\u001b[39;00m\n\u001b[1;32m      5\u001b[0m expanded_image_array \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mexpand_dims(image_array, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)  \u001b[39m# Expand the dimensions to match the batch size\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/utils/image_utils.py:422\u001b[0m, in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(path, pathlib\u001b[39m.\u001b[39mPath):\n\u001b[1;32m    421\u001b[0m         path \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(path\u001b[39m.\u001b[39mresolve())\n\u001b[0;32m--> 422\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(path, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    423\u001b[0m         img \u001b[39m=\u001b[39m pil_image\u001b[39m.\u001b[39mopen(io\u001b[39m.\u001b[39mBytesIO(f\u001b[39m.\u001b[39mread()))\n\u001b[1;32m    424\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path/to/your/image.jpg'"
     ]
    }
   ],
   "source": [
    "# Load the image\n",
    "image_path = \"data_pad.jpg\"\n",
    "image = load_img(image_path, target_size=(32, 32))  # Resize the image to match the input size of the CNN\n",
    "image_array = img_to_array(image)  # Convert the image to a numpy array\n",
    "expanded_image_array = tf.expand_dims(image_array, axis=0)  # Expand the dimensions to match the batch size\n",
    "\n",
    "# Preprocess the image\n",
    "preprocessed_image = preprocess_input(expanded_image_array)\n",
    "\n",
    "# Load the pre-trained CNN model\n",
    "model = model_d\n",
    "\n",
    "# Make predictions on the image\n",
    "predictions = model.predict(preprocessed_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
